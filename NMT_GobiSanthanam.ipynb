{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_project.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "colab_type": "code",
        "id": "z6hXdw7oAPeO",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import keras\n",
        "import sklearn\n",
        "from keras import optimizers\n",
        "import nltk\n",
        "import string as st\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM,GRU,Dense,Embedding,RepeatVector,TimeDistributed,Dropout,Bidirectional\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iVwAzUG1APeU",
        "colab": {}
      },
      "source": [
        "# Data will be in txt format.So, convert data in to dataframe using pandas \n",
        "data = pd.read_csv('deu.txt', delimiter='\\t', names=['English', 'German'])\n",
        "data_copy=data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "THuyKyQEAPef",
        "colab": {}
      },
      "source": [
        "reduced_data_set=data_copy[:160000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sPjKAdAVAPei",
        "colab": {}
      },
      "source": [
        "# Reduced data size\n",
        "reduced_data_set=reduced_data_set.reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1IbQcoJXAPeq"
      },
      "source": [
        "**Data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tp1c-twMAPes",
        "colab": {}
      },
      "source": [
        "en_max_len=0\n",
        "deu_max_len=0\n",
        "# lang_max_len=0\n",
        "# Remove punctuations in all the records. \n",
        "#Also, find the record with the maximum word length in both the languages.\n",
        "#This is done to create a fized encoding length for both the languages.\n",
        "for index, row in reduced_data_set.iterrows():\n",
        "    row['English']=row['English'].translate(str.maketrans('', '', st.punctuation)).lower()\n",
        "    if len(row['English'].split())>en_max_len:\n",
        "        en_max_len=len(row['English'].split())\n",
        "    row['German']=row['German'].translate(str.maketrans('', '', st.punctuation)).lower()\n",
        "    if len(row['German'].split())>deu_max_len:\n",
        "        deu_max_len=len(row['German'].split())  \n",
        "    # if deu_max_len > en_max_len:\n",
        "    #     lang_max_len=deu_max_len\n",
        "    # else:\n",
        "    #     lang_max_len=en_max_len"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zauy4-NFAPez",
        "outputId": "a4400f81-d797-4cf3-d7da-5b07d3a8adee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Map the words to integers using keras based tokenizer\n",
        "en_tokenizer=Tokenizer()\n",
        "deu_tokenizer=Tokenizer()\n",
        "\n",
        "en_tokenizer.fit_on_texts(reduced_data_set['English'].to_numpy())\n",
        "en_vocabulary_size = len(en_tokenizer.word_index) + 1\n",
        "\n",
        "deu_tokenizer.fit_on_texts(reduced_data_set['German'].to_numpy())\n",
        "deu_vocabulary_size = len(deu_tokenizer.word_index) + 1\n",
        "\n",
        "print('English Vocabulary Size:', en_vocabulary_size)\n",
        "print('Deutch Vocabulary Size:',deu_vocabulary_size)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English Vocabulary Size: 12820\n",
            "Deutch Vocabulary Size: 25698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "E81Eeg7CAPe3"
      },
      "source": [
        "**Split data in to training data and test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xi40YKtUAPe4",
        "colab": {}
      },
      "source": [
        "#Split the data in to ~80% for training set and ~20% for testing set\n",
        "data_split = np.random.rand(len(reduced_data_set)) <= 0.9\n",
        "train_data = reduced_data_set[data_split]\n",
        "test_data = reduced_data_set[~data_split]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1Jx0hYhgGpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_data = reduced_data_set[:100000]\n",
        "# test_data = reduced_data_set[100000:120000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tTQEeqGWAPe8",
        "outputId": "3d7a668d-daaf-4c38-dc42-5edfb56503b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#Shape of the training set and test set\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(144046, 2)\n",
            "(15954, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q-vRA-6gAPe_"
      },
      "source": [
        "**Convert data in to numpy array**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ftxI7XkcAPfA",
        "colab": {}
      },
      "source": [
        "#Convert dataframe in to numpy array\n",
        "train_data_np=train_data.to_numpy()\n",
        "test_data_np=test_data.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "hjvtFZuMAPfD"
      },
      "source": [
        "**Encode and split the data in to training and test data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m-KKAHpdAPfE",
        "colab": {}
      },
      "source": [
        "# Convert text in to encoded numbers. Also, padding is done with zeroes to maintain equal length for both languagge data.\n",
        "def encode_data(language_tokenizer, length, all_data):\n",
        "    encoded_data = language_tokenizer.texts_to_sequences(all_data)\n",
        "    padded_data = pad_sequences(encoded_data, maxlen=length, padding='post')\n",
        "    return padded_data\n",
        "\n",
        "trainX = encode_data(deu_tokenizer, deu_max_len, train_data_np[:, 1])\n",
        "trainY = encode_data(en_tokenizer, en_max_len, train_data_np[:, 0])\n",
        "testX = encode_data(deu_tokenizer, deu_max_len, test_data_np[:, 1])\n",
        "testY = encode_data(en_tokenizer, en_max_len, test_data_np[:, 0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mTNIsbZ-APfM",
        "colab": {}
      },
      "source": [
        "#Convert mapped words in to normal words\n",
        "def convert_integers_to_words(word_index, tokenizer):\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == word_index:\n",
        "            return word\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dy29ZTLTAPfQ"
      },
      "source": [
        "**Decode the predictions after training of model is finished**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3XsWeyIQAPfR",
        "colab": {}
      },
      "source": [
        "# Decode the predictions in to words\n",
        "def decode_data(model_prediction):\n",
        "    prediction_text=list()\n",
        "    for sentence in prediction:\n",
        "        converted_sentence = list()\n",
        "        for word_index in range(len(sentence)):\n",
        "            word = convert_integers_to_words(sentence[word_index], en_tokenizer)\n",
        "            if word_index > 0:\n",
        "                if (word == convert_integers_to_words(sentence[word_index-1], en_tokenizer)) or (word == None):\n",
        "                    converted_sentence.append('')\n",
        "                else:\n",
        "                    converted_sentence.append(word)\n",
        "\n",
        "            else:\n",
        "                if(word == None):\n",
        "                    converted_sentence.append('')\n",
        "                else:\n",
        "                    converted_sentence.append(word)            \n",
        "\n",
        "        prediction_text.append(' '.join(converted_sentence))\n",
        "        \n",
        "    return prediction_text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ip2jhnpaAPfU",
        "colab": {}
      },
      "source": [
        "#Build a sequence model using keras\n",
        "def build_model(lang1_vocab, lang2_vocab, lang1_max_len, lang2_max_len, units):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(lang1_vocab, units, input_length=lang1_max_len,input_shape=(lang1_max_len,), mask_zero=True))\n",
        "    model.add(LSTM(units))\n",
        "    model.add(RepeatVector(lang2_max_len))\n",
        "    model.add((LSTM(units, return_sequences=True)))\n",
        "    model.add(Dense(lang2_vocab, activation='softmax'))\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B9j_FSDhAPfY",
        "colab": {}
      },
      "source": [
        "model = build_model(deu_vocabulary_size, en_vocabulary_size, deu_max_len, en_max_len, 512)\n",
        "rms_optimizer = optimizers.RMSprop(lr=0.001)\n",
        "model.compile(optimizer=rms_optimizer, loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywp9AUMRr8Pa",
        "colab_type": "code",
        "outputId": "65b5321b-ad8b-4518-9586-eb5b4c6c0546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 19, 512)           13157376  \n",
            "_________________________________________________________________\n",
            "lstm_11 (LSTM)               (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "repeat_vector_6 (RepeatVecto (None, 11, 512)           0         \n",
            "_________________________________________________________________\n",
            "lstm_12 (LSTM)               (None, 11, 512)           2099200   \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 11, 12820)         6576660   \n",
            "=================================================================\n",
            "Total params: 23,932,436\n",
            "Trainable params: 23,932,436\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6X6bms13oL7o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'model.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SeuupNM_APff",
        "outputId": "cb343d02-6c66-4442-c7c4-3b3a46dc1be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history=model.fit(trainX, trainY.reshape(trainY.shape[0], trainY.shape[1], 1),epochs=20, batch_size=512, validation_split = 0.1, callbacks=[checkpoint], verbose=1)"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 129641 samples, validate on 14405 samples\n",
            "Epoch 1/20\n",
            "129641/129641 [==============================] - 57s 437us/step - loss: 3.1059 - acc: 0.5575 - val_loss: 4.2875 - val_acc: 0.3674\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.28753, saving model to model.h5\n",
            "Epoch 2/20\n",
            "129641/129641 [==============================] - 49s 381us/step - loss: 2.6030 - acc: 0.5959 - val_loss: 4.1089 - val_acc: 0.4002\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.28753 to 4.10890, saving model to model.h5\n",
            "Epoch 3/20\n",
            "129641/129641 [==============================] - 49s 381us/step - loss: 2.2656 - acc: 0.6351 - val_loss: 3.8988 - val_acc: 0.4253\n",
            "\n",
            "Epoch 00003: val_loss improved from 4.10890 to 3.89882, saving model to model.h5\n",
            "Epoch 4/20\n",
            "129641/129641 [==============================] - 49s 379us/step - loss: 1.9675 - acc: 0.6693 - val_loss: 3.4299 - val_acc: 0.4606\n",
            "\n",
            "Epoch 00004: val_loss improved from 3.89882 to 3.42994, saving model to model.h5\n",
            "Epoch 5/20\n",
            "129641/129641 [==============================] - 49s 379us/step - loss: 1.7115 - acc: 0.6950 - val_loss: 3.2370 - val_acc: 0.4777\n",
            "\n",
            "Epoch 00005: val_loss improved from 3.42994 to 3.23701, saving model to model.h5\n",
            "Epoch 6/20\n",
            "129641/129641 [==============================] - 49s 379us/step - loss: 1.5084 - acc: 0.7165 - val_loss: 3.1145 - val_acc: 0.4912\n",
            "\n",
            "Epoch 00006: val_loss improved from 3.23701 to 3.11451, saving model to model.h5\n",
            "Epoch 7/20\n",
            "129641/129641 [==============================] - 49s 379us/step - loss: 1.3456 - acc: 0.7358 - val_loss: 3.1055 - val_acc: 0.4976\n",
            "\n",
            "Epoch 00007: val_loss improved from 3.11451 to 3.10553, saving model to model.h5\n",
            "Epoch 8/20\n",
            "129641/129641 [==============================] - 49s 379us/step - loss: 1.2143 - acc: 0.7526 - val_loss: 2.9504 - val_acc: 0.5069\n",
            "\n",
            "Epoch 00008: val_loss improved from 3.10553 to 2.95036, saving model to model.h5\n",
            "Epoch 9/20\n",
            "129641/129641 [==============================] - 49s 379us/step - loss: 1.1031 - acc: 0.7682 - val_loss: 3.1240 - val_acc: 0.5025\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 2.95036\n",
            "Epoch 10/20\n",
            "129641/129641 [==============================] - 49s 379us/step - loss: 1.0076 - acc: 0.7830 - val_loss: 2.8597 - val_acc: 0.5194\n",
            "\n",
            "Epoch 00010: val_loss improved from 2.95036 to 2.85967, saving model to model.h5\n",
            "Epoch 11/20\n",
            "129641/129641 [==============================] - 49s 378us/step - loss: 0.9227 - acc: 0.7965 - val_loss: 2.8793 - val_acc: 0.5232\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 2.85967\n",
            "Epoch 12/20\n",
            "129641/129641 [==============================] - 49s 377us/step - loss: 0.8485 - acc: 0.8099 - val_loss: 2.8117 - val_acc: 0.5278\n",
            "\n",
            "Epoch 00012: val_loss improved from 2.85967 to 2.81172, saving model to model.h5\n",
            "Epoch 13/20\n",
            "129641/129641 [==============================] - 49s 378us/step - loss: 0.7803 - acc: 0.8224 - val_loss: 3.0075 - val_acc: 0.5210\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 2.81172\n",
            "Epoch 14/20\n",
            "129641/129641 [==============================] - 49s 377us/step - loss: 0.7184 - acc: 0.8344 - val_loss: 2.9425 - val_acc: 0.5278\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 2.81172\n",
            "Epoch 15/20\n",
            "129641/129641 [==============================] - 49s 379us/step - loss: 0.6624 - acc: 0.8452 - val_loss: 3.0269 - val_acc: 0.5273\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 2.81172\n",
            "Epoch 16/20\n",
            "129641/129641 [==============================] - 49s 378us/step - loss: 0.6105 - acc: 0.8561 - val_loss: 3.0974 - val_acc: 0.5260\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 2.81172\n",
            "Epoch 17/20\n",
            "129641/129641 [==============================] - 49s 377us/step - loss: 0.5624 - acc: 0.8664 - val_loss: 3.0538 - val_acc: 0.5304\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 2.81172\n",
            "Epoch 18/20\n",
            "129641/129641 [==============================] - 49s 378us/step - loss: 0.5185 - acc: 0.8760 - val_loss: 3.0712 - val_acc: 0.5313\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 2.81172\n",
            "Epoch 19/20\n",
            "129641/129641 [==============================] - 49s 377us/step - loss: 0.4791 - acc: 0.8848 - val_loss: 3.1550 - val_acc: 0.5307\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 2.81172\n",
            "Epoch 20/20\n",
            "129641/129641 [==============================] - 49s 379us/step - loss: 0.4421 - acc: 0.8931 - val_loss: 3.1889 - val_acc: 0.5308\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 2.81172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bsownY6uAPfk",
        "colab": {}
      },
      "source": [
        "#Get predictions for text data \n",
        "model=load_model('model.h5')\n",
        "prediction = model.predict_classes(testX.reshape((testX.shape[0],testX.shape[1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v51DNL44v-B0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "d0765b43-6f4e-4f66-c701-c5871b2a72d1"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.legend(['train','validation'])\n",
        "plt.show()"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nulJKeYn/D95S2tDZu00YAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eFd7CjXTAPfq",
        "colab": {}
      },
      "source": [
        "#Decode the predictions\n",
        "prediction_text = decode_data(prediction)\n",
        "#Create a new dataframe for expected and predicted data\n",
        "pred_df = pd.DataFrame({'German':test_data['German'],'Expected' : test_data['English'], 'predicted' : prediction_text})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N88Ptx8MAPfu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "64b7dd91-d7dc-4bbf-e23a-9f3579d21089"
      },
      "source": [
        "#Display the expected and predicted data\n",
        "pred_df.iloc[7:12]"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>German</th>\n",
              "      <th>Expected</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>seien sie nett</td>\n",
              "      <td>be nice</td>\n",
              "      <td>be nice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>schwirr ab</td>\n",
              "      <td>beat it</td>\n",
              "      <td>get away</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>mach ’ne fliege</td>\n",
              "      <td>go away</td>\n",
              "      <td>get away</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>scher dich weg</td>\n",
              "      <td>go away</td>\n",
              "      <td>get away</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>verpiss dich</td>\n",
              "      <td>go away</td>\n",
              "      <td>get lost</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              German Expected          predicted\n",
              "71    seien sie nett  be nice   be nice         \n",
              "85        schwirr ab  beat it  get away         \n",
              "114  mach ’ne fliege  go away  get away         \n",
              "117   scher dich weg  go away  get away         \n",
              "120     verpiss dich  go away  get lost         "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxicELdLHeBu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "9e135b6e-b277-4007-ecf4-ccd6ce415676"
      },
      "source": [
        "pred_df.iloc[9000:9005]"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>German</th>\n",
              "      <th>Expected</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>90478</th>\n",
              "      <td>wozu brauchtest du eine kettensäge</td>\n",
              "      <td>why did you need a chainsaw</td>\n",
              "      <td>why did you need a chainsaw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90482</th>\n",
              "      <td>wozu habt ihr eine kettensäge gebraucht</td>\n",
              "      <td>why did you need a chainsaw</td>\n",
              "      <td>why did you need a chainsaw</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90484</th>\n",
              "      <td>warum hast du das zu tom gesagt</td>\n",
              "      <td>why did you say that to tom</td>\n",
              "      <td>why did you tell tom to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90507</th>\n",
              "      <td>warum hast du mir das nicht gesagt</td>\n",
              "      <td>why didnt you tell me that</td>\n",
              "      <td>why didnt you tell me</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90514</th>\n",
              "      <td>warum tun die menschen böses</td>\n",
              "      <td>why do people do bad things</td>\n",
              "      <td>why are people</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        German  ...                         predicted\n",
              "90478       wozu brauchtest du eine kettensäge  ...  why did you need a chainsaw     \n",
              "90482  wozu habt ihr eine kettensäge gebraucht  ...  why did you need a chainsaw     \n",
              "90484          warum hast du das zu tom gesagt  ...      why did you tell tom to     \n",
              "90507       warum hast du mir das nicht gesagt  ...       why didnt you tell me      \n",
              "90514             warum tun die menschen böses  ...            why are people        \n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-Wd58G8bAPf1",
        "colab": {}
      },
      "source": [
        "def evaluate_model(actual_data,predicted_data):\n",
        "    print('BLEU Score:',corpus_bleu(actual_data, prediction_text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5sgmpD2MAPf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8c131cc6-1908-45f9-ad0d-4f08bd6c4d77"
      },
      "source": [
        "evaluate_model(test_data_np[:,0],prediction_text)"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU Score: 0.7977105212768360\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}